{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Alloy (Python)","text":"<p>Python for logic. English for intelligence.</p> <p>Alloy lets you declare typed AI commands in Python, wire up tools, and route to multiple model providers with a consistent API.</p> <ul> <li>Typed commands via <code>@command(output=...)</code></li> <li>Simple <code>ask(...)</code> namespace for quick prompts</li> <li>Tool calling with contracts and validation</li> <li>Multi\u2011provider backends (OpenAI, Anthropic, Gemini, Ollama)</li> </ul> <p>See Getting Started for installation and a 2\u2011minute tutorial.</p>"},{"location":"backends/","title":"Backends &amp; Routing","text":"<p>Alloy auto-routes based on the <code>model</code> string:</p> <ul> <li>OpenAI: <code>gpt-*</code>, <code>gpt5*</code>, <code>openai*</code></li> <li>Anthropic: <code>claude*</code>, <code>anthropic*</code></li> <li>Gemini: <code>gemini*</code>, <code>google*</code> (uses <code>google-genai</code>)</li> <li>Ollama: <code>ollama:*</code> or <code>local:*</code></li> </ul> <p>Set <code>ALLOY_BACKEND=fake</code> to use a fake offline backend for examples.</p>"},{"location":"commands/","title":"Commands &amp; Tools","text":""},{"location":"commands/#commands","title":"Commands","text":"<p>Declare a command with <code>@command</code>. The function returns a prompt string. The decorator executes the model and parses output into the declared type.</p> <pre><code>from alloy import command\n\n@command(output=int)\ndef Compute() -&gt; str:\n    return \"Return 6*7 as a number.\"\n\nassert Compute() == 42\n</code></pre>"},{"location":"commands/#tools","title":"Tools","text":"<pre><code>from alloy import command, tool\n\n@tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Add two integers.\"\"\"\n    return a + b\n\n@command(output=int, tools=[add])\ndef UseAdd() -&gt; str:\n    return \"Use add(a,b) to compute 19+23. Return only the number.\"\n</code></pre>"},{"location":"commands/#ask","title":"Ask","text":"<pre><code>from alloy import ask\n\nprint(ask(\"Explain in one sentence.\"))\n</code></pre>"},{"location":"commands/#streaming","title":"Streaming","text":"<pre><code>from alloy import command, ask\n\n@command(output=str)\ndef Generate() -&gt; str:\n    return \"Write a haiku about alloy.\"\n\n# Iterate chunks (sync). For async commands, use `async for`.\nfor chunk in Generate.stream():\n    print(chunk, end=\"\")\n\nfor chunk in ask.stream(\"Explain briefly.\"):\n    print(chunk, end=\"\")\n</code></pre>"},{"location":"commands/#retries-and-error-handling","title":"Retries and error handling","text":"<pre><code>from alloy import command, configure\nfrom alloy.errors import CommandError\n\n# Global defaults\nconfigure(retry=2)  # retry transient errors twice\n\n@command(output=int)\ndef Maybe() -&gt; str:\n    return \"Return an integer between 1 and 10.\"\n\ntry:\n    print(Maybe())\nexcept CommandError as e:\n    print(\"Model error:\", e)\n</code></pre>"},{"location":"commands/#contracts-requireensure","title":"Contracts (require/ensure)","text":"<pre><code>from alloy import tool, require, ensure\n\n@tool\n@require(lambda x: x &gt;= 0, \"x must be non-negative\")\n@ensure(lambda r: r &gt;= 0, \"result must be non-negative\")\ndef sqrt_floor(x: int) -&gt; int:\n    \"\"\"Return floor(sqrt(x)).\"\"\"\n    import math\n    return int(math.sqrt(x))\n</code></pre>"},{"location":"configuration/","title":"Configuration","text":"<p>Alloy reads configuration from, in precedence order:</p> <ol> <li>Per-call overrides (e.g., <code>ask(..., model=...)</code>)</li> <li><code>configure(...)</code> and context scopes</li> <li>Environment variables (<code>ALLOY_*</code>)</li> <li>Built-in defaults (<code>model=\"gpt-5-mini\"</code>, <code>max_tool_turns=2</code>)</li> </ol>"},{"location":"configuration/#environment-variables","title":"Environment variables","text":"<ul> <li><code>ALLOY_MODEL</code></li> <li><code>ALLOY_TEMPERATURE</code></li> <li><code>ALLOY_MAX_TOKENS</code></li> <li><code>ALLOY_SYSTEM</code> or <code>ALLOY_DEFAULT_SYSTEM</code></li> <li><code>ALLOY_RETRY</code></li> <li><code>ALLOY_MAX_TOOL_TURNS</code></li> <li><code>ALLOY_EXTRA_JSON</code> (provider-specific)</li> </ul>"},{"location":"configuration/#programmatic","title":"Programmatic","text":"<pre><code>from alloy import configure\n\nconfigure(model=\"gpt-5-mini\", temperature=0.2)\n</code></pre>"},{"location":"contributing-docs/","title":"Contributing to Docs","text":"<ul> <li>Style: Use Google-style docstrings for public functions, classes, and modules.</li> <li>Local preview: <code>pip install -e '.[docs]'</code> then <code>make docs-serve</code>.</li> <li>Build check: <code>make docs-build</code> (uses <code>--strict</code>).</li> <li>PRs: Docs workflow builds for pull requests; deploy happens only on <code>main</code>.</li> </ul>"},{"location":"contributing-docs/#docstring-example-google-style","title":"Docstring example (Google style)","text":"<pre><code>def add(a: int, b: int) -&gt; int:\n    \"\"\"Add two integers.\n\n    Args:\n      a: First number.\n      b: Second number.\n\n    Returns:\n      The sum of a and b.\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<ul> <li>Basic: see <code>examples/basic_usage.py</code></li> <li>Tools: see <code>examples/tools_demo.py</code></li> </ul> <p>Run with <code>.env</code> loaded:</p> <pre><code>python examples/basic_usage.py\n</code></pre> <p>Offline demo:</p> <pre><code>ALLOY_BACKEND=fake python examples/basic_usage.py\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#install","title":"Install","text":"<ul> <li>All providers: <code>pip install \"alloy-ai[providers]\"</code></li> <li>Minimal (OpenAI only): <code>pip install alloy-ai</code></li> </ul> <p>Optional: <code>pip install -e '.[providers]'</code> to work on the repo in editable mode.</p>"},{"location":"getting-started/#configure-credentials","title":"Configure credentials","text":"<p>Create a <code>.env</code> in your project root:</p> <pre><code>OPENAI_API_KEY=sk-...\n</code></pre> <p>Optionally set <code>ANTHROPIC_API_KEY</code> or <code>GOOGLE_API_KEY</code> for other providers.</p>"},{"location":"getting-started/#first-command","title":"First command","text":"<pre><code>from alloy import command, ask\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n@command(output=float)\ndef ExtractPrice(text: str) -&gt; str:\n    \"\"\"Extract price from text.\"\"\"\n    return f\"Extract the price (number only) from: {text}\"\n\nprint(ExtractPrice(\"This item costs $49.99.\"))\nprint(ask(\"Say OK in one word.\"))\n</code></pre>"},{"location":"whats-new/","title":"What's New","text":"<p>Release notes and highlights. See full changelog for details.</p> <ul> <li>Changelog: https://github.com/openai/alloy-py/blob/main/CHANGELOG.md</li> <li>Releases: https://github.com/openai/alloy-py/releases</li> </ul>"},{"location":"whats-new/#unreleased","title":"Unreleased","text":"<ul> <li>Docs site (MkDocs + mkdocstrings)</li> <li>Google GenAI (gemini) via <code>google-genai</code> only</li> <li>Dependency refresh, MIT license</li> </ul>"},{"location":"api/alloy/","title":"alloy","text":""},{"location":"api/alloy/#alloy","title":"alloy","text":"<p>Alloy public API.</p> <p>Python for logic. English for intelligence.</p> <p>This is an initial scaffold of the v1.0 surface area.</p>"},{"location":"api/alloy/#alloy.CommandError","title":"CommandError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when a command fails to produce a valid result.</p>"},{"location":"api/alloy/#alloy.ToolError","title":"ToolError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when a tool contract fails or a tool invocation errors.</p>"},{"location":"api/alloy/#alloy.ConfigurationError","title":"ConfigurationError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when required configuration or provider backends are missing.</p>"},{"location":"api/alloy/#alloy.configure","title":"configure","text":"<pre><code>configure(**kwargs)\n</code></pre> <p>Set global defaults for Alloy execution.</p> Example <p>configure(model=\"gpt-4\", temperature=0.7)</p>"},{"location":"api/ask/","title":"Ask","text":""},{"location":"api/ask/#alloy.ask","title":"alloy.ask","text":""},{"location":"api/ask/#alloy.ask._AskNamespace","title":"_AskNamespace","text":""},{"location":"api/ask/#alloy.ask._AskNamespace.__call__","title":"__call__","text":"<pre><code>__call__(prompt, *, tools=None, context=None, **overrides)\n</code></pre> <p>Open-ended exploratory interface.</p> <p>Example: ask(\"What is quantum computing?\", tools=[search])</p>"},{"location":"api/command/","title":"Commands","text":""},{"location":"api/command/#alloy.command","title":"alloy.command","text":""},{"location":"api/command/#alloy.command.command","title":"command","text":"<pre><code>command(\n    fn=None,\n    *,\n    output=None,\n    tools=None,\n    model=None,\n    temperature=None,\n    max_tokens=None,\n    system=None,\n    retry=None,\n    retry_on=None\n)\n</code></pre> <p>Decorator to declare an AI-powered command.</p> <p>The wrapped function returns an English specification (prompt). This decorator executes the model with optional tools and parses the result into the annotated return type.</p>"},{"location":"api/config/","title":"Config","text":""},{"location":"api/config/#alloy.config","title":"alloy.config","text":""},{"location":"api/config/#alloy.config._config_from_env","title":"_config_from_env","text":"<pre><code>_config_from_env()\n</code></pre> <p>Build a Config from process environment variables (optional).</p> Supported variables <ul> <li>ALLOY_MODEL (str)</li> <li>ALLOY_TEMPERATURE (float)</li> <li>ALLOY_MAX_TOKENS (int)</li> <li>ALLOY_SYSTEM or ALLOY_DEFAULT_SYSTEM (str)</li> <li>ALLOY_RETRY (int)</li> <li>ALLOY_EXTRA_JSON (JSON object for provider-specific extras)</li> </ul>"},{"location":"api/config/#alloy.config.configure","title":"configure","text":"<pre><code>configure(**kwargs)\n</code></pre> <p>Set global defaults for Alloy execution.</p> Example <p>configure(model=\"gpt-4\", temperature=0.7)</p>"},{"location":"api/config/#alloy.config.use_config","title":"use_config","text":"<pre><code>use_config(temp_config)\n</code></pre> <p>Context manager to apply a config within a scope.</p>"},{"location":"api/config/#alloy.config.get_config","title":"get_config","text":"<pre><code>get_config(overrides=None)\n</code></pre> <p>Return the effective config (global -&gt; context -&gt; overrides).</p>"},{"location":"api/errors/","title":"Errors","text":""},{"location":"api/errors/#alloy.errors","title":"alloy.errors","text":""},{"location":"api/errors/#alloy.errors.AlloyError","title":"AlloyError","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for Alloy.</p>"},{"location":"api/errors/#alloy.errors.CommandError","title":"CommandError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when a command fails to produce a valid result.</p>"},{"location":"api/errors/#alloy.errors.ToolError","title":"ToolError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when a tool contract fails or a tool invocation errors.</p>"},{"location":"api/errors/#alloy.errors.ConfigurationError","title":"ConfigurationError","text":"<p>               Bases: <code>AlloyError</code></p> <p>Raised when required configuration or provider backends are missing.</p>"},{"location":"api/tool/","title":"Tools","text":""},{"location":"api/tool/#alloy.tool","title":"alloy.tool","text":""},{"location":"api/tool/#alloy.tool.tool","title":"tool","text":"<pre><code>tool(fn=None)\n</code></pre> <p>Decorator to mark a Python function as an Alloy tool.</p> <p>The decorated callable still runs locally in Python, but carries metadata and contracts to teach the AI how to use it.</p>"},{"location":"api/types/","title":"Types","text":""},{"location":"api/types/#alloy.types","title":"alloy.types","text":""},{"location":"api/models/anthropic/","title":"Anthropic","text":""},{"location":"api/models/anthropic/#alloy.models.anthropic","title":"alloy.models.anthropic","text":""},{"location":"api/models/anthropic/#alloy.models.anthropic.AnthropicBackend","title":"AnthropicBackend","text":"<p>               Bases: <code>ModelBackend</code></p> <p>Anthropic Claude backend (minimal implementation).</p> <p>This implementation requires the <code>anthropic</code> SDK. If it isn't installed, calls raise ConfigurationError. Tool-calling support is not implemented in v1.</p>"},{"location":"api/models/base/","title":"Base","text":""},{"location":"api/models/base/#alloy.models.base","title":"alloy.models.base","text":""},{"location":"api/models/base/#alloy.models.base.ModelBackend","title":"ModelBackend","text":"<p>Abstract provider interface.</p> <p>Concrete backends implement completion and tool-calling behavior.</p>"},{"location":"api/models/gemini/","title":"Gemini","text":""},{"location":"api/models/gemini/#alloy.models.gemini","title":"alloy.models.gemini","text":""},{"location":"api/models/gemini/#alloy.models.gemini.GeminiBackend","title":"GeminiBackend","text":"<p>               Bases: <code>ModelBackend</code></p> <p>Google Gemini backend (minimal implementation).</p> <p>Supports the <code>google-genai</code> SDK. If it isn't installed, calls raise ConfigurationError. Tool-calling and structured outputs are not implemented in this scaffold.</p>"},{"location":"api/models/ollama/","title":"Ollama","text":""},{"location":"api/models/ollama/#alloy.models.ollama","title":"alloy.models.ollama","text":""},{"location":"api/models/ollama/#alloy.models.ollama.OllamaBackend","title":"OllamaBackend","text":"<p>               Bases: <code>ModelBackend</code></p> <p>Ollama backend using the <code>ollama</code> Python SDK.</p> <p>Tool-calling and streaming are not implemented in this scaffold.</p>"},{"location":"api/models/openai/","title":"OpenAI","text":""},{"location":"api/models/openai/#alloy.models.openai","title":"alloy.models.openai","text":""},{"location":"api/models/openai/#alloy.models.openai.OpenAIBackend","title":"OpenAIBackend","text":"<p>               Bases: <code>ModelBackend</code></p> <p>OpenAI backend using Chat Completions.</p> <p>Requires the <code>openai</code> SDK. If it is not installed, a ConfigurationError is raised at call time so importing the module does not crash users without the SDK.</p>"}]}